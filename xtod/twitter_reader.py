#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Twitter æ¨æ–‡é˜…è¯»å’Œæ–‡æ¡£ç”Ÿæˆå·¥å…·
ä¸“é—¨è®¾è®¡ç”¨äºå¤ç”¨ Chrome ç™»å½•çŠ¶æ€ï¼Œå®Œæ•´è¯»å– Twitter thread
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional


class TwitterThreadReader:
    """Twitter Thread è¯»å–å™¨ - ä½¿ç”¨ Chrome DevTools"""

    # æå–æ¨æ–‡æ•°æ®çš„ JavaScript
    EXTRACT_TWEETS_SCRIPT = """
    () => {
        const result = {
            author: null,
            total_tweets: 0,
            tweets: [],
            extracted_at: new Date().toISOString()
        };

        // è·å–æ‰€æœ‰ article å…ƒç´ ï¼ˆæ¯ä¸ªæ¨æ–‡ä¸€ä¸ªï¼‰
        const articles = document.querySelectorAll('article[data-testid="tweet"]');

        articles.forEach((article, index) => {
            try {
                // æå–ä½œè€…ä¿¡æ¯
                const authorLink = article.querySelector('a[role="link"][href^="/"]');
                const authorName = article.querySelector('[data-testid="User-Name"]');
                const author = {
                    handle: authorLink ? authorLink.getAttribute('href').substring(1) : '',
                    name: authorName ? authorName.textContent.split('\\n')[0] : ''
                };

                // ç¬¬ä¸€æ¡æ¨æ–‡çš„ä½œè€…ä½œä¸ºçº¿ç¨‹ä½œè€…
                if (index === 0) {
                    result.author = author;
                }

                // æå–æ¨æ–‡æ–‡æœ¬
                const tweetText = article.querySelector('[data-testid="tweetText"]');
                const text = tweetText ? tweetText.innerText : '';

                // æå–æ—¶é—´
                const timeElement = article.querySelector('time');
                const timestamp = timeElement ? timeElement.getAttribute('datetime') : '';
                const timeText = timeElement ? timeElement.textContent : '';

                // æå–å›¾ç‰‡
                const images = [];
                const imageElements = article.querySelectorAll('[data-testid="tweetPhoto"] img');
                imageElements.forEach(img => {
                    if (img.src && img.src.includes('pbs.twimg.com/media')) {
                        // è·å–åŸå›¾ URL
                        const originalUrl = img.src
                            .replace(/\\?.*$/, '')
                            .replace('&name=small', '')
                            .replace('&name=medium', '')
                            .replace('&name=large', '') + '?format=jpg&name=4096x4096';
                        images.push({
                            url: originalUrl,
                            alt: img.alt || ''
                        });
                    }
                });

                // æå–äº’åŠ¨æ•°æ®
                const getMetric = (testid) => {
                    const elem = article.querySelector(`[data-testid="${testid}"]`);
                    if (!elem) return 0;
                    const text = elem.getAttribute('aria-label') || elem.textContent || '';
                    const match = text.match(/([\\d,]+)/);
                    if (!match) return 0;
                    return parseInt(match[1].replace(/,/g, ''), 10);
                };

                const metrics = {
                    replies: getMetric('reply'),
                    retweets: getMetric('retweet'),
                    likes: getMetric('like'),
                    bookmarks: getMetric('bookmark')
                };

                // æ£€æŸ¥æ˜¯å¦æœ‰ "Show more" æŒ‰é’®
                const showMoreButton = article.querySelector('[data-testid="tweet-text-show-more-link"]');
                const isTruncated = showMoreButton !== null;

                if (text || images.length > 0) {
                    result.tweets.push({
                        index: index + 1,
                        author: author,
                        text: text,
                        is_truncated: isTruncated,
                        timestamp: timestamp,
                        time_text: timeText,
                        images: images,
                        metrics: metrics
                    });
                }
            } catch (e) {
                console.error('æå–æ¨æ–‡å¤±è´¥:', e);
            }
        });

        result.total_tweets = result.tweets.length;
        return result;
    }
    """

    # å±•å¼€ "Show more" çš„ JavaScript
    EXPAND_TWEETS_SCRIPT = """
    () => {
        let expanded = 0;
        const buttons = document.querySelectorAll('[data-testid="tweet-text-show-more-link"]');

        buttons.forEach(button => {
            try {
                button.click();
                expanded++;
            } catch (e) {
                console.error('å±•å¼€å¤±è´¥:', e);
            }
        });

        return {
            total_buttons: buttons.length,
            expanded: expanded,
            message: `å±•å¼€äº† ${expanded} ä¸ªæŠ˜å çš„æ¨æ–‡`
        };
    }
    """

    # æ»šåŠ¨åŠ è½½è¯„è®ºåŒº
    SCROLL_TO_LOAD_SCRIPT = """
    (distance) => {
        window.scrollBy(0, distance || 500);
        return {
            scrollY: window.scrollY,
            scrollHeight: document.documentElement.scrollHeight
        };
    }
    """

    def __init__(self, chrome_devtools):
        """
        åˆå§‹åŒ– Twitter è¯»å–å™¨

        Args:
            chrome_devtools: Chrome DevTools MCP å®ä¾‹
        """
        self.chrome = chrome_devtools

    def navigate_to_tweet(self, url: str):
        """å¯¼èˆªåˆ°æ¨æ–‡ URL"""
        print(f"ğŸŒ æ­£åœ¨è®¿é—®: {url}")
        self.chrome.navigate_page(url=url, timeout=30000)

    def wait_for_load(self, seconds: int = 3):
        """ç­‰å¾…é¡µé¢åŠ è½½"""
        import time
        print(f"â³ ç­‰å¾…é¡µé¢åŠ è½½ {seconds} ç§’...")
        time.sleep(seconds)

    def expand_all_tweets(self):
        """å±•å¼€æ‰€æœ‰æŠ˜å çš„æ¨æ–‡"""
        print("ğŸ“– æ­£åœ¨å±•å¼€æ‰€æœ‰æŠ˜å çš„æ¨æ–‡...")
        result = self.chrome.evaluate_script(
            function=self.EXPAND_TWEETS_SCRIPT
        )

        result_data = json.loads(result) if isinstance(result, str) else result
        print(f"  âœ… {result_data.get('message', 'å±•å¼€å®Œæˆ')}")
        return result_data

    def scroll_and_load_replies(self, max_scrolls: int = 5):
        """æ»šåŠ¨é¡µé¢åŠ è½½è¯„è®ºåŒº"""
        print(f"ğŸ“œ æ­£åœ¨æ»šåŠ¨åŠ è½½è¯„è®ºåŒºï¼ˆæœ€å¤š {max_scrolls} æ¬¡ï¼‰...")

        for i in range(max_scrolls):
            result = self.chrome.evaluate_script(
                function=self.SCROLL_TO_LOAD_SCRIPT,
                args=[]
            )
            self.wait_for_load(2)
            print(f"  ç¬¬ {i+1}/{max_scrolls} æ¬¡æ»šåŠ¨å®Œæˆ")

    def extract_tweets_data(self) -> Dict:
        """æå–æ¨æ–‡æ•°æ®"""
        print("ğŸ“ æ­£åœ¨æå–æ¨æ–‡æ•°æ®...")

        result = self.chrome.evaluate_script(
            function=self.EXTRACT_TWEETS_SCRIPT
        )

        data = json.loads(result) if isinstance(result, str) else result
        print(f"âœ… æå–å®Œæˆï¼šå…± {data.get('total_tweets', 0)} æ¡æ¨æ–‡")

        return data

    def screenshot_tweet(self, tweet_index: int, output_path: str):
        """æˆªå›¾æŒ‡å®šçš„æ¨æ–‡"""
        # ä½¿ç”¨ CSS é€‰æ‹©å™¨å®šä½æ¨æ–‡
        selector_script = f"""
        () => {{
            const articles = document.querySelectorAll('article[data-testid="tweet"]');
            const article = articles[{tweet_index - 1}];
            if (!article) return null;

            return {{
                x: article.getBoundingClientRect().x,
                y: article.getBoundingClientRect().y + window.scrollY,
                width: article.offsetWidth,
                height: article.offsetHeight
            }};
        }}
        """

        # è·å–æ¨æ–‡ä½ç½®
        result = self.chrome.evaluate_script(function=selector_script)
        bounds = json.loads(result) if isinstance(result, str) else result

        if not bounds:
            print(f"  âš ï¸ æ¨æ–‡ #{tweet_index} æœªæ‰¾åˆ°")
            return False

        # æ»šåŠ¨åˆ°æ¨æ–‡ä½ç½®
        scroll_script = f"() => {{ window.scrollTo(0, {bounds['y'] - 100}); }}"
        self.chrome.evaluate_script(function=scroll_script)
        self.wait_for_load(1)

        # æˆªå›¾
        self.chrome.take_screenshot(filename=output_path)
        print(f"  âœ… æ¨æ–‡ #{tweet_index} æˆªå›¾å®Œæˆ")
        return True

    def download_image(self, image_url: str, output_path: str):
        """ä¸‹è½½å›¾ç‰‡"""
        try:
            import requests
            response = requests.get(image_url, timeout=30)
            if response.status_code == 200:
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                return True
            else:
                print(f"  âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"  âŒ å›¾ç‰‡ä¸‹è½½é”™è¯¯: {e}")
            return False

    def read_full_thread(
        self,
        url: str,
        output_dir: str,
        expand_replies: bool = True
    ) -> Dict:
        """
        å®Œæ•´è¯»å– Twitter thread

        Args:
            url: Twitter æ¨æ–‡ URL
            output_dir: è¾“å‡ºç›®å½•
            expand_replies: æ˜¯å¦å±•å¼€å¹¶è¯»å–è¯„è®ºåŒºçš„ä½œè€…å›å¤

        Returns:
            åŒ…å«æ‰€æœ‰æ¨æ–‡æ•°æ®çš„å­—å…¸
        """
        os.makedirs(output_dir, exist_ok=True)
        screenshots_dir = os.path.join(output_dir, 'screenshots')
        images_dir = os.path.join(output_dir, 'images')
        os.makedirs(screenshots_dir, exist_ok=True)
        os.makedirs(images_dir, exist_ok=True)

        # 1. è®¿é—® URL
        self.navigate_to_tweet(url)
        self.wait_for_load(3)

        # 2. å±•å¼€æ‰€æœ‰ "Show more"
        self.expand_all_tweets()
        self.wait_for_load(2)

        # 3. æå–ä¸»æ¨æ–‡æ•°æ®
        tweets_data = self.extract_tweets_data()

        # 4. å¦‚æœéœ€è¦ï¼Œæ»šåŠ¨åŠ è½½è¯„è®ºåŒº
        if expand_replies:
            self.scroll_and_load_replies(max_scrolls=5)
            self.wait_for_load(2)

            # å†æ¬¡å±•å¼€ï¼ˆè¯„è®ºåŒºå¯èƒ½æœ‰æ–°çš„æŠ˜å å†…å®¹ï¼‰
            self.expand_all_tweets()
            self.wait_for_load(2)

            # é‡æ–°æå–ï¼ˆåŒ…æ‹¬è¯„è®ºåŒºçš„æ¨æ–‡ï¼‰
            tweets_data = self.extract_tweets_data()

        # 5. è¿‡æ»¤ï¼šåªä¿ç•™ä½œè€…çš„æ¨æ–‡ï¼ˆæ„å»º threadï¼‰
        if tweets_data.get('author'):
            author_handle = tweets_data['author'].get('handle', '')
            if author_handle:
                original_count = len(tweets_data['tweets'])
                tweets_data['tweets'] = [
                    t for t in tweets_data['tweets']
                    if t['author']['handle'] == author_handle
                ]
                tweets_data['total_tweets'] = len(tweets_data['tweets'])
                filtered_count = original_count - tweets_data['total_tweets']
                if filtered_count > 0:
                    print(f"ğŸ” è¿‡æ»¤åï¼šä¿ç•™ {tweets_data['total_tweets']} æ¡ä½œè€…æ¨æ–‡ï¼ˆè¿‡æ»¤æ‰ {filtered_count} æ¡å…¶ä»–äººçš„æ¨æ–‡ï¼‰")

        # 6. æˆªå›¾æ¯æ¡æ¨æ–‡
        print(f"ğŸ“¸ æ­£åœ¨æˆªå›¾ {tweets_data['total_tweets']} æ¡æ¨æ–‡...")
        for i, tweet in enumerate(tweets_data['tweets'], 1):
            screenshot_path = os.path.join(screenshots_dir, f'tweet_{i}.png')
            if self.screenshot_tweet(i, screenshot_path):
                tweet['screenshot'] = screenshot_path

        # 7. ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
        print("ğŸ“¥ æ­£åœ¨ä¸‹è½½æ¨æ–‡ä¸­çš„å›¾ç‰‡...")
        image_count = 0
        for tweet in tweets_data['tweets']:
            tweet_images = []
            for img in tweet.get('images', []):
                image_count += 1
                image_path = os.path.join(images_dir, f'image_{image_count}.jpg')
                if self.download_image(img['url'], image_path):
                    tweet_images.append(image_path)
                    print(f"  âœ… å›¾ç‰‡ {image_count} ä¸‹è½½å®Œæˆ")
            tweet['downloaded_images'] = tweet_images

        # 8. ä¿å­˜å…ƒæ•°æ®
        metadata_path = os.path.join(output_dir, 'metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(tweets_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

        # 9. è¿”å›ç»“æœ
        result = {
            'url': url,
            'author': tweets_data.get('author'),
            'total_tweets': tweets_data['total_tweets'],
            'tweets': tweets_data['tweets'],
            'output_dir': output_dir,
            'screenshots_dir': screenshots_dir,
            'images_dir': images_dir,
            'metadata_path': metadata_path
        }

        print("\n" + "="*60)
        print("âœ… Twitter Thread è¯»å–å®Œæˆï¼")
        print(f"ğŸ“ æ¨æ–‡æ•°ï¼š{result['total_tweets']}")
        print(f"ğŸ–¼ï¸  å›¾ç‰‡æ•°ï¼š{image_count}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_dir}")
        print("="*60 + "\n")

        return result


def read_twitter_thread(url: str, chrome_devtools, output_dir: Optional[str] = None) -> Dict:
    """
    ç®€åŒ–çš„æ¥å£ï¼šè¯»å– Twitter thread

    Args:
        url: Twitter æ¨æ–‡ URL
        chrome_devtools: Chrome DevTools MCP å®ä¾‹
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤å½“å‰ç›®å½•ï¼‰

    Returns:
        åŒ…å«æ¨æ–‡æ•°æ®å’Œæ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    if output_dir is None:
        output_dir = os.path.join(os.getcwd(), 'twitter_output')

    reader = TwitterThreadReader(chrome_devtools)
    return reader.read_full_thread(url, output_dir)
